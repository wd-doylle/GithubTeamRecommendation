{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_repo = {}\n",
    "repo_inds = {}\n",
    "repos = []\n",
    "n = 100\n",
    "with open('../contributors.json') as tmj:\n",
    "    i = 0\n",
    "    for tml in tmj.readlines()[:n]:\n",
    "        line = json.loads(tml)\n",
    "        if not line['repo'] in repo_inds:\n",
    "            repo_inds[line['repo']] = i\n",
    "            repos.append(line['repo'])\n",
    "            i += 1\n",
    "        else:\n",
    "            print(line['repo'])\n",
    "#         cntr = 0\n",
    "        for user in line['contributors']:\n",
    "            if not user['login'] in user_repo:\n",
    "                user_repo[user['login']] = {}\n",
    "            user_repo[user['login']][line['repo']] = user['contributions']\n",
    "#             cntr += user['contributions']\n",
    "#         print(len(line['contributors']),cntr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for user in user_repo:\n",
    "    total_contri = 0\n",
    "    for repo in user_repo[user]:\n",
    "        total_contri += user_repo[user][repo]\n",
    "    for repo in user_repo[user]:\n",
    "        user_repo[user][repo] /= total_contri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(torch.nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(len(repo_inds), 64)\n",
    "        self.fc2 = torch.nn.Linear(64, len(repo_inds))\n",
    "        self.activation = torch.nn.Sigmoid()\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "cuda0 = torch.device('cuda:0')\n",
    "sae = SAE()\n",
    "sae.cuda(device=cuda0)\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.RMSprop(sae.parameters(), lr = 0.001, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: 0.07228681675572259\n",
      "epoch: 2 loss: 0.059526044882241606\n",
      "epoch: 3 loss: 0.059334540945703694\n",
      "epoch: 4 loss: 0.06234421338736745\n",
      "epoch: 5 loss: 0.34641065070008437\n",
      "epoch: 6 loss: 0.512658834244691\n",
      "epoch: 7 loss: 1.3353166893898913\n",
      "epoch: 8 loss: 1.6740623646956698\n",
      "epoch: 9 loss: 3.0270266706877766\n",
      "epoch: 10 loss: 1.8502485324082494\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 10\n",
    "batch_size = 10\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    train_loss = 0\n",
    "    s = 0.\n",
    "    for user in user_repo:\n",
    "        input = torch.zeros(len(repo_inds),device=cuda0)\n",
    "        for repo in user_repo[user]:\n",
    "            input[repo_inds[repo]] = user_repo[user][repo]\n",
    "        target = input.clone()\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = len(repo_inds)/torch.sum(target.data > 0).item()\n",
    "            loss.backward()\n",
    "            train_loss += np.sqrt(loss.item()*mean_corrector)\n",
    "            s += 1.\n",
    "            if s % batch_size = 0:\n",
    "                optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('nwolek', {'jamoma/JamomaCore': 707})\n",
      "tensor([707.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
      "          0.,   0.,   0.,   0.], device='cuda:0')\n",
      "tensor([ 0.9301,  0.8789,  0.9872,  1.8451,  0.8184,  6.3266, -5.6941,  5.8376,\n",
      "         0.8607,  0.9516,  4.3175, -0.9121, -1.2570,  0.8614,  4.1121,  1.0031,\n",
      "         0.8729,  0.9900,  0.9983,  0.8944,  0.8618,  0.9794,  0.8625,  0.8253,\n",
      "         1.0058,  0.9667,  0.7908, -1.7578,  0.8795, -0.8641, -4.1347,  0.9970,\n",
      "         9.3978,  0.9412, -1.8774,  0.9179,  0.9606, -1.7045,  0.9865,  0.9992,\n",
      "         0.9079,  0.9763,  0.9362,  0.8459,  0.9678,  0.9975, -2.5872,  0.9516,\n",
      "         0.7737,  3.7130, -0.2630,  0.9273,  1.0008,  0.9929,  0.9340,  0.9460,\n",
      "         2.1807,  0.8001, -1.4392,  1.7679,  2.6197,  0.9892,  0.9166,  4.1250,\n",
      "         0.9660, -5.8203,  6.5454,  0.9958,  6.7090,  0.8508,  1.0958,  0.8407,\n",
      "         0.9175,  0.9976,  4.0409,  0.9933,  5.6676,  1.0065,  0.9851,  1.0010,\n",
      "         0.9267,  0.9580,  0.9653,  0.6715,  0.9162,  1.0074,  0.9527,  1.0075,\n",
      "         0.9933,  0.9917,  0.8867,  1.0019,  1.0027,  0.9899,  0.9758,  0.9011,\n",
      "         0.8381,  0.9902,  0.9713,  0.9496], device='cuda:0',\n",
      "       grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "sae.eval()\n",
    "input = torch.zeros(len(repo_inds),device=cuda0)\n",
    "item = list(user_repo.items())[1]\n",
    "print(item)\n",
    "for repo in item[1]:\n",
    "    input[repo_inds[repo]] = user_repo[item[0]][repo]\n",
    "print(input)\n",
    "print(sae(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {}\n",
    "with open(\"../network.json\") as nj:\n",
    "    j = json.load(nj)\n",
    "    nodes = j['nodes']\n",
    "    aware = j['aware']\n",
    "    for u1,g in enumerate(aware):\n",
    "        n1 = nodes[u1]\n",
    "        if not n1 in user_repo:\n",
    "            continue\n",
    "        if not n1 in graph:\n",
    "            graph[n1] = {}\n",
    "        for u in g:\n",
    "            u2 = int(u)\n",
    "            n2 = nodes[u2]\n",
    "            if not n2 in user_repo:\n",
    "                continue\n",
    "            if not n2 in graph:\n",
    "                graph[n2] = {}\n",
    "            if not n2 in graph[n1]:\n",
    "                graph[n1][n2] = 0\n",
    "            if not n1 in graph[n2]:\n",
    "                graph[n2][n1] = 0\n",
    "            graph[n1][n2] += len(g[u])\n",
    "            graph[n2][n1] += len(g[u])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n1 in graph:\n",
    "    ss = 0\n",
    "    for n2 in graph[n1]:\n",
    "        ss += graph[n1][n2]\n",
    "    for n2 in graph[n1]:\n",
    "        graph[n1][n2] /= ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ilanbiala', {'tamird': 0.014285714285714285, 'othiym23': 0.014285714285714285, 'alanshaw': 0.014285714285714285, 'sebv': 0.014285714285714285, 'bcoe': 0.014285714285714285, 'jdalton': 0.014285714285714285, 'epelc': 0.014285714285714285, 'eddiemonge': 0.014285714285714285, 'ashleygwilliams': 0.014285714285714285, 'boneskull': 0.014285714285714285, 'zeke': 0.014285714285714285, 'ritch': 0.014285714285714285, 'snlacks': 0.014285714285714285, 'JulianWielga': 0.014285714285714285, 'Narretz': 0.014285714285714285, 'gkalpak': 0.02857142857142857, 'lukeis': 0.014285714285714285, 'dandv': 0.014285714285714285, 'admc': 0.014285714285714285, 'zhongsp': 0.014285714285714285, 'naomiblack': 0.014285714285714285, 'gdi2290': 0.02857142857142857, 'rgbkrk': 0.014285714285714285, 'nykolaslima': 0.014285714285714285, 'shyndman': 0.014285714285714285, 'SBoudrias': 0.02857142857142857, 'indexzero': 0.02857142857142857, 'marcysutton': 0.014285714285714285, 'Keats': 0.014285714285714285, 'EladBezalel': 0.014285714285714285, 'JaKXz': 0.014285714285714285, 'PaulMougel': 0.014285714285714285, 'dougwilson': 0.04285714285714286, 'shinnn': 0.014285714285714285, 'phated': 0.014285714285714285, 'benmccann': 0.014285714285714285, 'Fishrock123': 0.02857142857142857, 'JuanCaicedo': 0.014285714285714285, 'terinjokes': 0.014285714285714285, 'alexgorbatchev': 0.014285714285714285, 'usta': 0.014285714285714285, 'jdesboeufs': 0.014285714285714285, 'jesselpalmer': 0.014285714285714285, 'typotter': 0.014285714285714285, 'isaacs': 0.014285714285714285, 'ryanjbaxter': 0.014285714285714285, 'rvagg': 0.014285714285714285, 'zbjornson': 0.014285714285714285, 'kevinsawicki': 0.02857142857142857, 'ajoslin': 0.014285714285714285, 'ThomasBurleson': 0.014285714285714285, 'forresto': 0.014285714285714285, 'rschmukler': 0.02857142857142857, 'robertmesserle': 0.014285714285714285, 'petebacondarwin': 0.014285714285714285, 'trainerbill': 0.014285714285714285, 'dozingcat': 0.014285714285714285, 'mikeal': 0.014285714285714285, 'smehrbrodt': 0.014285714285714285, 'caitp': 0.014285714285714285, 'matsko': 0.014285714285714285})\n"
     ]
    }
   ],
   "source": [
    "print(list(graph.items())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Nilson', {'jamoma/JamomaCore': 1.0})\n",
      "tensor([1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0')\n",
      "tensor([  1.8558,   1.7540,   1.9687,   3.4959,   1.6331,  12.4999, -11.4527,\n",
      "         11.5777,   1.7164,   1.8981,   8.6066,  -1.8578,  -2.6023,   1.7172,\n",
      "          8.1961,   1.9991,   1.7396,   1.9732,   1.9891,   1.7827,   1.7176,\n",
      "          1.9516,   1.7192,   1.6440,   2.0036,   1.9275,   1.5777,  -3.4062,\n",
      "          1.7546,  -1.7206,  -8.3156,   1.9891,  18.8251,   1.8776,  -3.7470,\n",
      "          1.8311,   1.9164,  -3.3923,   1.9682,   1.9937,   1.8113,   1.9477,\n",
      "          1.8678,   1.6890,   1.9309,   1.9903,  -5.2569,   1.9005,   1.5290,\n",
      "          7.4114,  -0.5948,   1.8499,   1.9970,   1.9814,   1.8647,   1.8875,\n",
      "          4.3610,   1.5942,  -3.1549,   3.3996,   5.2193,   1.9743,   1.8287,\n",
      "          8.1671,   1.9244, -11.7533,  13.0479,   1.9868,  13.3753,   1.6971,\n",
      "          2.1863,   1.6770,   1.8309,   1.9914,   8.0519,   1.9829,  11.2928,\n",
      "          2.0045,   1.9665,   1.9941,   1.8507,   1.9127,   1.9268,   1.3385,\n",
      "          1.8282,   2.0007,   1.9015,   2.0119,   1.9831,   1.9795,   1.7688,\n",
      "          1.9997,   1.9925,   1.9771,   1.9475,   1.7978,   1.6717,   1.9769,\n",
      "          1.9383,   1.8947], device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "u1 = 0\n",
    "input = torch.zeros(len(repo_inds),device=cuda0)\n",
    "item = list(user_repo.items())[u1]\n",
    "print(item)\n",
    "for repo in item[1]:\n",
    "    input[repo_inds[repo]] = user_repo[item[0]][repo]\n",
    "print(input)\n",
    "pred = sae(input)\n",
    "for n2 in graph[item[0]]:\n",
    "    input = torch.zeros(len(repo_inds),device=cuda0)\n",
    "    for repo in user_repo[n2]:\n",
    "        input[repo_inds[repo]] = user_repo[n2][repo]\n",
    "    output = sae(input)\n",
    "    pred += output*graph[item[0]][n2]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_to_k(ary,k,key=lambda x:x,reversed=False):\n",
    "    k = min(k,len(ary))\n",
    "    for i in range(k):\n",
    "        for j in range(len(ary)-1-i):\n",
    "            if not reversed:\n",
    "                if key(ary[len(ary)-1-j]) < key(ary[len(ary)-2-j]):\n",
    "                    ary[len(ary)-1-j],ary[len(ary)-2-j] = ary[len(ary)-2-j],ary[len(ary)-1-j]\n",
    "            else:\n",
    "                if key(ary[len(ary)-1-j]) > key(ary[len(ary)-2-j]):\n",
    "                    ary[len(ary)-1-j],ary[len(ary)-2-j] = ary[len(ary)-2-j],ary[len(ary)-1-j]\n",
    "    return ary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"npm/npm\", 18.82508659362793]\n",
      "[\"magnumripper/JohnTheRipper\", 13.375268936157227]\n",
      "[\"saltstack/salt\", 13.04786205291748]\n",
      "[\"aws/aws-sdk-java\", 12.49986457824707]\n",
      "[\"wallabag/wallabag\", 11.577651977539062]\n",
      "[\"irungentoo/toxcore\", 11.292764663696289]\n",
      "[\"NaturalNode/natural\", 8.606616020202637]\n",
      "[\"openMF/community-app\", 8.196128845214844]\n",
      "[\"rust-lang/cargo\", 8.167122840881348]\n",
      "[\"apache/flink\", 8.051855087280273]\n",
      "[\"philc/vimium\", 7.411432266235352]\n",
      "[\"boot2docker/boot2docker\", 5.21930456161499]\n",
      "[\"tomaka/glutin\", 4.360992908477783]\n",
      "[\"marklogic/node-client-api\", 3.4958651065826416]\n",
      "[\"mesosphere/marathon\", 3.3996007442474365]\n",
      "[\"sass/libsass\", 2.186338186264038]\n",
      "[\"owncloud/core\", 2.011935234069824]\n",
      "[\"angular/material\", 2.004453420639038]\n",
      "[\"yesodweb/yesod\", 2.0035769939422607]\n",
      "[\"lukasz-madon/awesome-remote-job\", 2.0007212162017822]\n",
      "[\"jekyll/jekyll\", 1.9997336864471436]\n",
      "[\"magento/magento2\", 1.9991129636764526]\n",
      "[\"KoffeinFlummi/AGM\", 1.9970226287841797]\n",
      "[\"aidancbrady/Mekanism\", 1.9941158294677734]\n",
      "[\"facebook/pop\", 1.9936800003051758]\n",
      "[\"skwp/dotfiles\", 1.992467999458313]\n",
      "[\"strongloop/generator-loopback\", 1.9914166927337646]\n",
      "[\"biocore/qiime\", 1.990305781364441]\n",
      "[\"chenshuo/muduo\", 1.9890992641448975]\n",
      "[\"KhronosGroup/glTF\", 1.9890923500061035]\n"
     ]
    }
   ],
   "source": [
    "k = 30\n",
    "pred = pred.cpu()\n",
    "recs = sort_to_k(list(range(len(pred))),k,key=lambda i:pred[i],reversed=True)\n",
    "for rec in recs[:k]:\n",
    "    print(json.dumps((repos[rec],pred[rec].item())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
